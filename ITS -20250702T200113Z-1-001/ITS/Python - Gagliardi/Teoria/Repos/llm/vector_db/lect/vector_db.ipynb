{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Introduzione ai Database Vettoriali**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I database vettoriali sono progettati per archiviare e gestire dati rappresentati come vettori. Questi sono comunemente utilizzati per lavorare con dati non strutturati come testo, immagini, video e audio, trasformati in rappresentazioni numeriche chiamate vector embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un database vettoriale permette di:\n",
    "\n",
    "- Archiviare vettori (vector embeddings) in modo efficiente.\n",
    "- Eseguire ricerche rapide basate su somiglianze tra i vettori.\n",
    "- Eeguire query basate su linguaggio naturale.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Vector Embedding**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un vector embedding è una rappresentazione numerica di un dato non strutturato in uno spazio multidimensionale.\n",
    "\n",
    "- I vettori catturano caratteristiche salienti dei dati, come il significato semantico nel testo o dettagli visivi in un'immagine.\n",
    "- Sono generati da modelli di machine learning come BERT per il testo o ResNet per immagini.\n",
    "\n",
    "Esempio:\n",
    "La frase \"Il gatto dorme\" può essere trasformata in un vettore numerico, come \n",
    "[0.3,0.8,0.2,...], che rappresenta il suo significato."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](./3dplot-500x381.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Ricerca semantica**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La ricerca semantica trova i vettori più simili a un dato vettore di input. Questo processo è basato sul calcolo della similarità o della distanza tra vettori. Le metriche più comuni includono:\n",
    "\n",
    "- Cosine Similarity: Misura l'angolo tra due vettori, ignorando la lunghezza. Due vettori sono più simili quando l'angolo è piccolo.\n",
    " \n",
    "- Euclidean Distance: Misura la distanza lineare tra due vettori. Minore è la distanza, maggiore è la somiglianza.\n",
    "\n",
    " \n",
    " \n",
    "La ricerca restituisce gli elementi più vicini al vettore di input, ordinati in base alla loro similarità.\n",
    "\n",
    "Esempio:\n",
    "Se cerchi un documento simile a una frase, il sistema troverà documenti che hanno vettori vicini al vettore della frase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](./cosine_sim-500x426.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Vector Indexing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Il vector indexing organizza i vettori per ottimizzare la ricerca. \n",
    "Senza un indice, il confronto diretto di ogni vettore con milioni di altri richiederebbe troppo tempo.\n",
    "\n",
    "\n",
    "La Nearest Neighbor Search (ricerca del vicino più prossimo) è il cuore della vector search. Si tratta di trovare i vettori che si trovano a distanza minima da un vettore di input.\n",
    "La ricerca utilizza appunto l'indice per identificare i vicini più prossimi in base a una metrica di distanza.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](./vector-indexing.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Chunking**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nell'ambito dei database vettoriali, il chunking è una tecnica essenziale che consente di suddividere grandi quantità di dati in blocchi più piccoli, facilitando l'elaborazione e il recupero delle informazioni.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [ChromaDb](https://www.trychroma.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](./hrm4.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ICTS23-25.497\\AppData\\Local\\miniforge3\\envs\\llm_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is artificial intelligence?\n",
      "Document: Machine learning is a subset of artificial intelligence., Score: 0.681416392326355\n",
      "Document: Artificial intelligence is transforming the world., Score: 0.7204954624176025\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Initialize a sentence transformer model for generating embeddings\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Set up ChromaDB\n",
    "client = chromadb.Client()\n",
    "\n",
    "# Create a collection in memory\n",
    "collection = client.get_or_create_collection(name=\"test_collection\")\n",
    "\n",
    "# Sample data\n",
    "documents = [\n",
    "    \"Artificial intelligence is transforming the world.\",\n",
    "    \"Machine learning is a subset of artificial intelligence.\",\n",
    "    \"Deep learning models are powerful for image and text data.\",\n",
    "    \"ChromaDB is a vector database for efficient similarity search.\"\n",
    "]\n",
    "\n",
    "# Generate embeddings for the documents\n",
    "embeddings = model.encode(documents).tolist()\n",
    "\n",
    "# Add documents and embeddings to the collection\n",
    "ids: list[str] = []\n",
    "for i in range(len(embeddings)):\n",
    "    ids.append(f\"doc{i + 1}\")\n",
    "collection.add(\n",
    "    documents=documents,\n",
    "    embeddings=embeddings,\n",
    "    ids=ids\n",
    ")\n",
    "\n",
    "# Query the database\n",
    "query = \"What is artificial intelligence?\"\n",
    "query_embedding = model.encode([query]).tolist()\n",
    "\n",
    "# Perform similarity search\n",
    "results = collection.query(\n",
    "    query_embeddings=query_embedding,\n",
    "    n_results=2  # Number of similar documents to retrieve\n",
    ")\n",
    "\n",
    "# Display results\n",
    "print(\"Query:\", query)\n",
    "for doc, score in zip(results[\"documents\"][0], results[\"distances\"][0]):\n",
    "    print(f\"Document: {doc}, Score: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Retrieval-Augmented Generation (RAG)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il Retrieval-Augmented Generation (RAG) è un approccio innovativo nell'ambito dei modelli di intelligenza artificiale, che combina recupero di informazioni e generazione di linguaggio naturale per produrre risposte più accurate e contestuali."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Come funziona RAG?**\n",
    "\n",
    "1. Fase di Recupero (Retrieval): l'applicazione ricerca le informazioni richieste nel databae vettoriale, attraverso la ricerca semantica\n",
    "\n",
    "2. Fase di Generazione (Generation): Le informazioni recuperate vengono inserite direttamente nel prompt, per generare un certo tipo di risposta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](./how-rag-works.jpg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
