{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***“Language is a process of free creation; its laws and principles are fixed, but the manner in which the principles of generation are used is free and infinitely varied. Even the interpretation and use of words involves a process of free creation.”***\n",
    "\n",
    "\n",
    "[Noam Chomsky](https://it.wikipedia.org/wiki/Noam_Chomsky) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **L'approccio di Chomsky: Grammatiche Generative**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chomsky sviluppò il concetto di grammatiche generative, un approccio formale per descrivere le regole sintattiche che governano le lingue. Questo metodo rappresenta il linguaggio come un sistema gerarchico, in cui frasi grammaticalmente corrette sono generate da un insieme finito di regole ricorsive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le grammatiche generative sono spesso rappresentate come grammatiche libere dal contesto (CFG - Context-Free Grammars). Una CFG è composta da:\n",
    "\n",
    "- Simboli terminali: le parole del linguaggio.\n",
    "- Simboli non terminali: rappresentano categorie sintattiche (es. frase nominale, frase verbale).\n",
    "- Produzioni: regole che descrivono come i simboli non terminali possono essere espansi.\n",
    "- Simbolo iniziale: il punto di partenza per generare una frase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](./Cgisf-tgg.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A l i c e a m m i r ò d a A l i c e\n",
      "A l i c e v i d e d a A l i c e\n",
      "A l i c e c a m m i n ò n e l C a r l o\n",
      "C a r l o c a m m i n ò u n a p a r c o\n",
      "A l i c e c a m m i n ò n e l i l t e l e s c o p i o\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Definiamo una grammatica generativa con regole di produzione\n",
    "grammatica = {\n",
    "    \"S\": [[\"SN\", \"SV\"]],  # Frase = Sintagma Nominale + Sintagma Verbale\n",
    "    \"SN\": [[\"Det\", \"N\"], [\"NomeProprio\"]],  # Sintagma Nominale = Determinante + Nome O Nome Proprio\n",
    "    \"SV\": [[\"V\", \"SN\"], [\"V\", \"SP\"], [\"V\"]],  # Sintagma Verbale = Verbo + Sintagma Nominale O Verbo + Sintagma Preposizionale O Verbo\n",
    "    \"SP\": [[\"P\", \"SN\"]],  # Sintagma Preposizionale = Preposizione + Sintagma Nominale\n",
    "    \"Det\": [\"il\", \"la\", \"un\", \"una\"],  # Determinanti\n",
    "    \"N\": [\"gatto\", \"cane\", \"uomo\", \"donna\", \"telescopio\", \"parco\"],  # Nomi\n",
    "    \"V\": [\"vide\", \"camminò\", \"ammirò\"],  # Verbi\n",
    "    \"P\": [\"nel\", \"con\", \"da\"],  # Preposizioni\n",
    "    \"NomeProprio\": [\"Alice\", \"Bob\", \"Carlo\"]  # Nomi propri\n",
    "}\n",
    "\n",
    "# Funzione per generare una frase ricorsivamente\n",
    "def genera_frase(simbolo):\n",
    "    if simbolo not in grammatica:  # Caso base: simbolo terminale\n",
    "        return simbolo\n",
    "    regola = random.choice(grammatica[simbolo])  # Scegli una regola di produzione casuale\n",
    "    # Genera ricorsivamente ogni parte della regola di produzione\n",
    "    return \" \".join(genera_frase(sym) for sym in regola)\n",
    "\n",
    "# Genera e stampa alcune frasi\n",
    "for _ in range(5):  # Genera 5 frasi\n",
    "     print(genera_frase(\"S\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Word2Vec**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Tomas Mikolov et al. - 2013](https://arxiv.org/abs/1301.3781)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2Vec è un modello di embedding sviluppato da Google che rappresenta le parole come vettori in uno spazio vettoriale continuo. Questo modello utilizza reti neurali per catturare le relazioni semantiche e sintattiche tra le parole basandosi sul contesto in cui appaiono nei testi. Esistono due architetture principali:\n",
    "\n",
    "- Continuous Bag of Words (CBOW): Predice una parola dato il contesto circostante.\n",
    "  È più veloce da addestrare ed efficace su dataset piccoli.\n",
    "\n",
    "- Skip-Gram: Predice il contesto dato una parola.\n",
    "  Più lento, ma cattura meglio parole rare.\n",
    "\n",
    "L'output è un vettore per ogni parola nel vocabolario, dove parole con significati simili avranno vettori vicini nello spazio vettoriale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***“You shall know a word by the company it keeps” J.R. Firth***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ![image](./skip_cbow.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parole simili a 'gatto':\n",
      "('sul', 0.18338043987751007)\n",
      "('giocano', 0.16944551467895508)\n",
      "('amici', 0.11253979057073593)\n",
      "('con', 0.08992018550634384)\n",
      "('la', 0.0887191891670227)\n",
      "\n",
      "Vettore per 'gatto': [-0.0164842   0.0185973  -0.00039535 -0.00393404  0.00920712 -0.00818939\n",
      "  0.00548756  0.0138809   0.01213075 -0.01502045  0.01876344  0.00934409\n",
      "  0.00793155 -0.01248777  0.01692049 -0.00429953  0.01765153 -0.01072486\n",
      " -0.01625774  0.0136501   0.00334184 -0.00439831  0.01902801  0.01898867\n",
      " -0.01954821  0.00500946  0.01231233  0.00774454  0.00404634  0.00086046\n",
      "  0.00134587 -0.00764071 -0.01427978 -0.0041787   0.00784797  0.01763706\n",
      "  0.0185183  -0.01195334 -0.01880494  0.01952805  0.00685973  0.010332\n",
      "  0.01256502 -0.00560969  0.014645    0.00566094  0.0057428  -0.00476109\n",
      " -0.00625791 -0.00473962]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "# Dati di esempio (piccolo corpus)\n",
    "corpus = [\n",
    "    \"Il gatto salta sul tappeto\",\n",
    "    \"Il cane corre nel parco\",\n",
    "    \"I bambini giocano con la palla\",\n",
    "    \"La palla è sul tappeto\",\n",
    "    \"Il gatto e il cane sono amici\"\n",
    "]\n",
    "\n",
    "# Pre-processamento: tokenizzazione\n",
    "tokenized_corpus = [simple_preprocess(sentence) for sentence in corpus]\n",
    "\n",
    "# Addestramento del modello Word2Vec\n",
    "model = Word2Vec(sentences=tokenized_corpus, vector_size=50, window=3, min_count=1, workers=4, sg=1)  # sg=1 per Skip-Gram\n",
    "\n",
    "# Esempio di utilizzo: parole più \"vicine\" a \"gatto\"\n",
    "similar_words = model.wv.most_similar(\"gatto\", topn=5)\n",
    "print(\"Parole simili a 'gatto':\")\n",
    "for sw in similar_words:\n",
    "    print(sw)\n",
    "\n",
    "# Vettore per la parola \"gatto\"\n",
    "vector = model.wv['gatto']\n",
    "print(\"\\nVettore per 'gatto':\", vector)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
